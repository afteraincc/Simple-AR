### 简介

需要有WIFI功能的嵌入式芯片，ESP32芯片是带WIFI功能中最常用的一款了。另外开发板选择了NodeMCU-32S，主要是兼容Arduino，资料多，方便开发。

### 网络连接流程

流程的关键步骤是`反向连接`：嵌入式设备非常不方便输入，所以由AR设备生成`个人热点`的SSID和密码，手机按照这个来配置热点。

- 如何重置`个人热点`配置

	先按`RESET`按键复位，然后快速按`IO0`按键，会重置配置，配置会显示在屏幕上。

### 内存

显示屏分辨率240x240，一张图需要的内存量： 240x240x2=115200字节。ESP32无法分配出这样大小的连续内存...（有方法能实现的，但是要魔改底层模块代码），所以无法使用常见的双帧方案来提高刷新率/并行处理。

### 性能

ESP32的性能对图像处理来说是不够的，测试下来解码240x240的JPEG也就8帧左右。

改成直接传输未压缩BMP图片，发现瓶颈出现在WIFI速率上，未优化的简单测试只能4帧/秒，3.5Mbps左右。查了一下[官方文档](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-guides/wifi.html#esp32-wi-fi-throughput)能到20Mbps，但是需要重新编译内核参数等复杂操作。

### 视频流协议

ESP32的性能/内存等不满足一般的视频压缩流（例如MP4/H264等），选择最简单的MJPEG，实际上就是一张一张连续的JPEG图片。需要注意的是JPEG是一种压缩算法，压缩的码流数据要使用容器或文件格式进行 封装后保存或传输，参考[JFIF](https://www.w3.org/Graphics/JPEG/)

在传输的数据流中识别两种图片边界的关键点是JFIF规范了：

- 开头SOI`Start Of Image`对应十六进制 0xFFD8

- 结尾EOI`End Of Image`对应十六进制 0xFFD9

### 跳帧处理

主要还是内存不足（参考前面的`内存`部分）。JPEG的一般压缩率是10:1，但是最终是和图像复杂度有关系，内存申请上要稍微冗余多一点。即使这样也无法完全保证不出现不够的情况。

所以增加了跳帧的处理，如果JPEG图像过大时忽略。

方案选择的是在设备端实现，超出申请的内存时，从开头覆盖内存，但是保持结尾EOI的处理。而不是手机压缩时判断超出尺寸后忽略，避免耦合问题。

### 显示驱动TFT_eSPI库

配置分辨率/管针脚序号等时，官方提供的默认方案是修改库代码。这个方案对代码管理不友好，从上游更新一次代码，就需要记住手工修改一次库代码。

官方提供了另外一个较好的解决方案，任意目录下增加一个固定文件名`tft_setup.h`的配置文件。但是这个需要修改工程的编译参数才能实现，不同的IDE有不同的配置方法，所以最后在IDE层面又不统一了...

- Visual Studio Code + platformio

	配置文件`platformio.ini`增加`build_flags = -I include/tft`，然后`tft_setup.h`放在`include/tft`目录下

### TJpg_Decoder库

Visual Studio Code + platformio提供的TJpg_Decoder库版本非常低（只有0.2.0版本），代码中有inline函数，然后编译器无法兼容这种语法。这个库的新版本是解决了这个问题的，所以需要手工安装：同步TJpg_Decoder最新代码到`lib/TJpg_Decoder`目录即可